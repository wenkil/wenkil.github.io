

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/titleIcon.png">
  <link rel="icon" href="/img/titleIcon.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="description" content="">
  <meta name="author" content="John Doe">
  <meta name="keywords" content="">
  <meta name="description" content="在前面一篇Langgraph学习4的文章中，基本实现了一个能够进行Web搜索的AI助手。尽管搜索工具可以获取网络信息，但常常只返回搜索结果的简短摘要或链接，而不是完整内容。本篇我们将进一步扩展这个助手，让它能够抓取并分析网页内容，从而提供更深入的信息。 1. 搜索→抓取→总结的工作流首先，需要设计一个更复杂的工作流： chat_bot → search_tool → crawl4ai_tool →">
<meta property="og:type" content="article">
<meta property="og:title" content="Langgraph学习6：WebAgent支持网页内容抓取">
<meta property="og:url" content="http://example.com/2025/04/12/Langgraph%E5%AD%A6%E4%B9%A06%EF%BC%9AWebAgent%E6%94%AF%E6%8C%81%E7%BD%91%E9%A1%B5%E5%86%85%E5%AE%B9%E6%8A%93%E5%8F%96/index.html">
<meta property="og:site_name" content="Wenkil的开发笔记">
<meta property="og:description" content="在前面一篇Langgraph学习4的文章中，基本实现了一个能够进行Web搜索的AI助手。尽管搜索工具可以获取网络信息，但常常只返回搜索结果的简短摘要或链接，而不是完整内容。本篇我们将进一步扩展这个助手，让它能够抓取并分析网页内容，从而提供更深入的信息。 1. 搜索→抓取→总结的工作流首先，需要设计一个更复杂的工作流： chat_bot → search_tool → crawl4ai_tool →">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/img/blog/AI/langgraph/web_crawl_graph-2025-04-12_22-35-50.png">
<meta property="og:image" content="http://example.com/img/blog/AI/langgraph/web_crawl_graph-2025-04-12_22-35-50.png">
<meta property="og:image" content="http://example.com/img/blog/AI/langgraph/2025-04-12_22-36-58.png">
<meta property="og:image" content="http://example.com/img/blog/AI/langgraph/2025-04-12_23-16-16.png">
<meta property="article:published_time" content="2025-04-12T15:12:00.000Z">
<meta property="article:modified_time" content="2025-04-12T15:57:21.333Z">
<meta property="article:author" content="John Doe">
<meta property="article:tag" content="Langgraph">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="http://example.com/img/blog/AI/langgraph/web_crawl_graph-2025-04-12_22-35-50.png">
  
  <title>Langgraph学习6：WebAgent支持网页内容抓取 - Wenkil的开发笔记</title>

  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/css/bootstrap.min.css" />


  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/github-markdown-css@4/github-markdown.min.css" />
  <link  rel="stylesheet" href="/lib/hint/hint.min.css" />

  
    
    
      
      <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@10/styles/github-gist.min.css" />
    
  

  
    <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3/dist/jquery.fancybox.min.css" />
  


<!-- 主题依赖的图标库，不要自行修改 -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_ba1fz6golrf.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_kmeydafke9r.css">


<link  rel="stylesheet" href="/css/main.css" />

<!-- 自定义样式保持在最底部 -->


  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    var CONFIG = {"hostname":"example.com","root":"/","version":"1.8.12","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"right","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"copy_btn":true,"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"baidu":null,"google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname"}},"search_path":"/local-search.xml"};
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
<meta name="generator" content="Hexo 5.4.0"></head>


<body>
  <header style="height: 70vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>Wenkil的开发笔记</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                首页
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                归档
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                分类
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                标签
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                关于
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              &nbsp;<i class="iconfont icon-search"></i>&nbsp;
            </a>
          </li>
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

    <div class="banner" id="banner" parallax=true
         style="background: url('/img/blog.png') no-repeat center center;
           background-size: cover;">
      <div class="full-bg-img">
        <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
          <div class="page-header text-center fade-in-up">
            <span class="h2" id="subtitle" title="Langgraph学习6：WebAgent支持网页内容抓取">
              
            </span>

            
              <div class="mt-3">
  
  
    <span class="post-meta">
      <i class="iconfont icon-date-fill" aria-hidden="true"></i>
      <time datetime="2025-04-12 23:12" pubdate>
        2025年4月12日 23:12:00
      </time>
    </span>
  
</div>

<div class="mt-1">
  
    <span class="post-meta mr-2">
      <i class="iconfont icon-chart"></i>
      33k 字
    </span>
  

  

  
  
</div>

            
          </div>

          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="d-none d-lg-block col-lg-2"></div>
    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div class="py-5" id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">Langgraph学习6：WebAgent支持网页内容抓取</h1>
            
            <div class="markdown-body">
              <p>在前面一篇Langgraph学习4的文章中，基本实现了一个能够进行Web搜索的AI助手。尽管搜索工具可以获取网络信息，但常常只返回搜索结果的简短摘要或链接，而不是完整内容。本篇我们将进一步扩展这个助手，让它能够抓取并分析网页内容，从而提供更深入的信息。</p>
<h2 id="1-搜索→抓取→总结的工作流"><a href="#1-搜索→抓取→总结的工作流" class="headerlink" title="1. 搜索→抓取→总结的工作流"></a>1. 搜索→抓取→总结的工作流</h2><p>首先，需要设计一个更复杂的工作流：</p>
<div class="code-wrapper"><pre><code class="hljs ada">chat_bot → search_tool → crawl4ai_tool → summary_bot → <span class="hljs-keyword">END</span></code></pre></div>

<p>以下是本篇代码跑通后的实际graph图例：</p>
<p><img src="/img/blog/AI/langgraph/web_crawl_graph-2025-04-12_22-35-50.png" srcset="/img/loading.gif" lazyload></p>
<p>这个工作流包括四个主要节点：</p>
<ol>
<li>chat_bot：分析用户请求，决定是否需要搜索信息</li>
<li>search_tool：执行网络搜索，获取相关链接</li>
<li>crawl4ai_tool：抓取搜索返回的链接内容</li>
<li>summary_bot：分析抓取的内容，生成综合回复</li>
</ol>
<p>这种链式结构可以让我们实现”搜索→抓取→总结”的完整信息处理流程。</p>
<h2 id="2-网页抓取工具"><a href="#2-网页抓取工具" class="headerlink" title="2. 网页抓取工具"></a>2. 网页抓取工具</h2><p>首先需要实现一个网页抓取工具。这里我们使用一个自定义的网页爬虫工具：</p>
<div class="code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">from</span> crawl_tool <span class="hljs-keyword">import</span> quick_crawl_tool

<span class="hljs-meta">@tool</span>
<span class="hljs-keyword">async</span> <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">crawl4ai_tool</span>(<span class="hljs-params">query: <span class="hljs-built_in">list</span>[<span class="hljs-built_in">str</span>]</span>):</span>
    <span class="hljs-string">&quot;&quot;&quot;用于爬取网页内容。接收URL列表，返回对应网页的内容。&quot;&quot;&quot;</span>
    urls = query
    result = <span class="hljs-keyword">await</span> quick_crawl_tool(urls)
    <span class="hljs-keyword">return</span> &#123;<span class="hljs-string">&quot;result&quot;</span>: result&#125;</code></pre></div>

<p>这个工具接收URL列表作为输入，返回抓取到的网页内容。使用<code>async</code>定义为异步函数，可以并行抓取多个网页，提高效率。</p>
<p>注意：这里依赖了自己封装的crea4ai的爬取工具 <code>crawl_tool</code>，该模块包含了爬虫的具体实现。</p>
<h2 id="3-爬取网页内容节点"><a href="#3-爬取网页内容节点" class="headerlink" title="3. 爬取网页内容节点"></a>3. 爬取网页内容节点</h2><p>接下来，我们需要实现爬取网页内容的节点：</p>
<div class="code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">async</span> <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">crawl4ai_tool_node</span>(<span class="hljs-params">state: MessagesState</span>):</span>
    <span class="hljs-string">&quot;&quot;&quot;爬取网页内容工具节点&quot;&quot;&quot;</span>
    last_message = state[<span class="hljs-string">&quot;messages&quot;</span>][-<span class="hljs-number">1</span>]
    urls = last_message.content
    
    <span class="hljs-comment"># 调用爬虫工具获取结果</span>
    tool_response = <span class="hljs-keyword">await</span> crawl4ai_tool.ainvoke(&#123;<span class="hljs-string">&quot;query&quot;</span>: urls&#125;)
    
    messages = []
    <span class="hljs-comment"># 创建ToolMessage并添加到列表</span>
    messages.append(ToolMessage(
        content=tool_response.get(<span class="hljs-string">&#x27;result&#x27;</span>, tool_response), 
        tool_call_id=last_message.<span class="hljs-built_in">id</span>
    ))
    
    <span class="hljs-keyword">return</span> &#123;<span class="hljs-string">&quot;messages&quot;</span>: messages&#125;</code></pre></div>

<p>这个节点函数的作用是：</p>
<ol>
<li>从上一个节点（搜索工具）获取URL列表</li>
<li>调用网页抓取工具获取这些URL的内容</li>
<li>将抓取结果打包为ToolMessage返回</li>
</ol>
<p>需要注意的是，这里我们假设搜索工具返回的是URL列表。在实际实现中可能需要进行更复杂的处理，例如从搜索结果中提取URL。</p>
<h2 id="4-总结节点"><a href="#4-总结节点" class="headerlink" title="4. 总结节点"></a>4. 总结节点</h2><p>对抓取到的网页内容进行总结分析是关键步骤。我们使用另一个LLM实例来完成这个任务：</p>
<div class="code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">async</span> <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">summary_bot_node</span>(<span class="hljs-params">state: MessagesState</span>):</span>
    <span class="hljs-string">&quot;&quot;&quot;总结网页内容的节点&quot;&quot;&quot;</span>
    messages = state[<span class="hljs-string">&quot;messages&quot;</span>]
    
    <span class="hljs-comment"># 找出用户的原始问题</span>
    human_messages = [msg <span class="hljs-keyword">for</span> msg <span class="hljs-keyword">in</span> messages <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(msg, HumanMessage)]
    human_message = human_messages[<span class="hljs-number">0</span>] <span class="hljs-keyword">if</span> human_messages <span class="hljs-keyword">else</span> <span class="hljs-literal">None</span>
    
    <span class="hljs-comment"># 找出最后一个工具消息（包含抓取的网页内容）</span>
    tool_messages = [msg <span class="hljs-keyword">for</span> msg <span class="hljs-keyword">in</span> messages <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(msg, ToolMessage)]
    last_tool_message = <span class="hljs-literal">None</span>
    <span class="hljs-keyword">for</span> msg <span class="hljs-keyword">in</span> <span class="hljs-built_in">reversed</span>(tool_messages):
        <span class="hljs-keyword">if</span> msg.content:
            last_tool_message = msg
            <span class="hljs-keyword">break</span>
    
    <span class="hljs-comment"># 创建系统消息</span>
    system_message = SystemMessage(content=<span class="hljs-string">&quot;&quot;&quot;</span>
<span class="hljs-string">        ## 你是一个擅长信息整理并总结的AI助手，请根据用户的问题，并结合工具给出的信息把回复总结出来。</span>
<span class="hljs-string">        - 如果有工具信息，正常执行总结；如果工具信息里是一些在线pdf，请把pdf的url和标题输出出来，告知用户来源自行查看。</span>
<span class="hljs-string">        - 如果发现工具没有返回信息，如【工具执行异常，无返回结果】，请根据用户的问题，给出简要回答，但必须带上说明，说明你无法生成详细总结的原因。并让用户再次自行尝试。</span>
<span class="hljs-string">        - 风格：排版按照markdown格式输出。热情，专业，有亲和力。</span>
<span class="hljs-string">    &quot;&quot;&quot;</span>)
    
    <span class="hljs-comment"># 构建消息列表</span>
    summary_messages = [system_message]
    
    <span class="hljs-keyword">if</span> human_message:
        summary_messages.append(human_message)
    
    <span class="hljs-keyword">if</span> last_tool_message:
        tool_result_message = ToolMessage(
            content=<span class="hljs-string">f&quot;以下是搜索和网页抓取工具返回的详细结果:\n\n<span class="hljs-subst">&#123;last_tool_message.content&#125;</span>&quot;</span>, 
            tool_call_id=last_tool_message.<span class="hljs-built_in">id</span>
        )
        summary_messages.append(tool_result_message)
    
    <span class="hljs-comment"># 调用摘要模型</span>
    <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(summary_messages) &gt; <span class="hljs-number">1</span>:
        response = <span class="hljs-keyword">await</span> summary_llm.ainvoke(summary_messages)
    <span class="hljs-keyword">else</span>:
        response = ToolMessage(
            content=<span class="hljs-string">&quot;工具执行异常，无返回结果。&quot;</span>, 
            tool_call_id=last_tool_message.<span class="hljs-built_in">id</span> <span class="hljs-keyword">if</span> last_tool_message <span class="hljs-keyword">else</span> <span class="hljs-string">&quot;error&quot;</span>
        )
    
    <span class="hljs-keyword">return</span> &#123;<span class="hljs-string">&quot;messages&quot;</span>: [response]&#125;</code></pre></div>

<p>总结节点的工作流程是：</p>
<ol>
<li>收集用户的原始问题</li>
<li>获取爬虫工具抓取的网页内容</li>
<li>构建一个精心设计的提示，要求模型根据用户问题和抓取内容生成总结</li>
<li>调用总结模型生成最终回复</li>
</ol>
<p>使用单独的总结模型而不是直接让主模型继续回复有几个好处：</p>
<ul>
<li>可以设计专门的提示，引导模型如何处理网页内容</li>
<li>避免主模型被过长的上下文困惑</li>
<li>便于单独优化总结功能</li>
</ul>
<h2 id="5-修改搜索工具节点"><a href="#5-修改搜索工具节点" class="headerlink" title="5. 修改搜索工具节点"></a>5. 修改搜索工具节点</h2><p>我们需要修改搜索工具节点，使其专注于处理搜索请求并提取URL：</p>
<div class="code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">async</span> <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">search_tool_node</span>(<span class="hljs-params">state: <span class="hljs-built_in">dict</span></span>):</span>
    <span class="hljs-string">&quot;&quot;&quot;搜索工具节点&quot;&quot;&quot;</span>
    result = []
    <span class="hljs-keyword">for</span> tool_call <span class="hljs-keyword">in</span> state[<span class="hljs-string">&quot;messages&quot;</span>][-<span class="hljs-number">1</span>].tool_calls:
        <span class="hljs-keyword">if</span> tool_call[<span class="hljs-string">&quot;name&quot;</span>] == <span class="hljs-string">&quot;search_tool&quot;</span>:
            tool = tools_by_name[tool_call[<span class="hljs-string">&quot;name&quot;</span>]]
            observation = tool.invoke(tool_call[<span class="hljs-string">&quot;args&quot;</span>])
            <span class="hljs-comment"># 处理搜索结果，提取URL</span>
            <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(observation, <span class="hljs-built_in">list</span>):
                urls = [item.get(<span class="hljs-string">&#x27;url&#x27;</span>, <span class="hljs-string">&#x27;&#x27;</span>) <span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> observation <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(item, <span class="hljs-built_in">dict</span>)]
                search_result = urls
            <span class="hljs-keyword">else</span>:
                search_result = observation
            result.append(ToolMessage(content=search_result, tool_call_id=tool_call[<span class="hljs-string">&quot;id&quot;</span>]))
    <span class="hljs-keyword">return</span> &#123;<span class="hljs-string">&quot;messages&quot;</span>: result&#125;</code></pre></div>

<p>这个节点现在会检查工具名称是否为”search_tool”，然后执行搜索并从结果中提取URL。<br><strong>这里需要注意：</strong> 如果使用的是TavilySearchResults，item里的链接字段是url，如果是使用的DuckDuckGoSearchResults，必须设置output_format=”list”，并且item里的链接字段是link。</p>
<p>另外，这里暂时没有处理非数组的情况，后续再进行完善~~</p>
<h2 id="6-构建完整工作流"><a href="#6-构建完整工作流" class="headerlink" title="6. 构建完整工作流"></a>6. 构建完整工作流</h2><p>现在我们可以构建完整的工作流：</p>
<div class="code-wrapper"><pre><code class="hljs python"><span class="hljs-comment"># 添加节点到图</span>
graph_builder.add_node(<span class="hljs-string">&quot;chat_bot&quot;</span>, chatbot_node)
graph_builder.add_node(<span class="hljs-string">&quot;search_tool&quot;</span>, search_tool_node)
graph_builder.add_node(<span class="hljs-string">&quot;crawl4ai_tool&quot;</span>, crawl4ai_tool_node)
graph_builder.add_node(<span class="hljs-string">&quot;summary_bot&quot;</span>, summary_bot_node)

<span class="hljs-comment"># 设置入口点</span>
graph_builder.set_entry_point(<span class="hljs-string">&quot;chat_bot&quot;</span>)

<span class="hljs-comment"># 添加条件边</span>
graph_builder.add_conditional_edges(
    <span class="hljs-string">&quot;chat_bot&quot;</span>,
    route_search_tool,
    path_map=&#123;<span class="hljs-string">&quot;search_tool&quot;</span>: <span class="hljs-string">&quot;search_tool&quot;</span>, <span class="hljs-string">&quot;END&quot;</span>: END&#125;
)

<span class="hljs-comment"># 添加其他边</span>
graph_builder.add_edge(<span class="hljs-string">&quot;search_tool&quot;</span>, <span class="hljs-string">&quot;crawl4ai_tool&quot;</span>)
graph_builder.add_edge(<span class="hljs-string">&quot;crawl4ai_tool&quot;</span>, <span class="hljs-string">&quot;summary_bot&quot;</span>)
graph_builder.add_edge(<span class="hljs-string">&quot;summary_bot&quot;</span>, END)</code></pre></div>

<p>与前一个版本不同，这次我们添加了一条明确的路径：从搜索工具到网页抓取工具，再到总结节点。这样确保了完整的信息处理流程。</p>
<p>工作流可视化如下：<br><img src="/img/blog/AI/langgraph/web_crawl_graph-2025-04-12_22-35-50.png" srcset="/img/loading.gif" lazyload></p>
<h2 id="7-准备系统提示和测试问题"><a href="#7-准备系统提示和测试问题" class="headerlink" title="7. 准备系统提示和测试问题"></a>7. 准备系统提示和测试问题</h2><p>为了测试这个增强版助手，我们准备了一个关于专业知识的查询：</p>
<div class="code-wrapper"><pre><code class="hljs python">system_message_str = <span class="hljs-string">&quot;&quot;&quot;</span>
<span class="hljs-string">    # 你是一个强大的AI助手，擅长搜索和分析网络信息。</span>
<span class="hljs-string">    ## 对于用户的问题，请先分析是否有足够知识进行回答，否则就要进行网络查询。如果需要查询实时或专业信息，请先使用[搜索工具]获取相关内容的链接。</span>
<span class="hljs-string">    ## 如果[搜索工具]返回的是链接，需要再用[爬虫工具]获取具体内容。</span>
<span class="hljs-string">    ## 请牢记今天的日期是&#123;today&#125;。</span>
<span class="hljs-string">&quot;&quot;&quot;</span>

user_message_str = <span class="hljs-string">&quot;&quot;&quot;</span>
<span class="hljs-string">    crawl4ai是什么？</span>
<span class="hljs-string">&quot;&quot;&quot;</span></code></pre></div>

<p>这个系统提示明确指出了工作流程：先进行分析是否有足够知识进行回答，然后在进行网络搜索获取链接，再使用爬虫工具获取内容。</p>
<h2 id="8-监听事件流"><a href="#8-监听事件流" class="headerlink" title="8. 监听事件流"></a>8. 监听事件流</h2><p>在执行过程中，我们监听不同类型的事件，提供更透明的执行过程：</p>
<div class="code-wrapper"><pre><code class="hljs python"><span class="hljs-comment"># 异步执行流式输出</span>
<span class="hljs-keyword">async</span> <span class="hljs-keyword">for</span> event <span class="hljs-keyword">in</span> graph.astream_events(initial_state, config=&#123;<span class="hljs-string">&quot;configurable&quot;</span>: &#123;<span class="hljs-string">&quot;thread_id&quot;</span>: <span class="hljs-string">&quot;8&quot;</span>&#125;&#125;, version=<span class="hljs-string">&quot;v2&quot;</span>):
    <span class="hljs-comment"># 定义一个变量接收所有on_chat_model_stream的值</span>
    <span class="hljs-comment"># print(&#x27;event------&gt;&#x27;,event,&#x27;\n\n&#x27;)</span>
    event_type = event[<span class="hljs-string">&#x27;event&#x27;</span>]
    <span class="hljs-comment"># print(&#x27;event_type------&gt;&#x27;,event_type,&#x27;\n\n&#x27;)</span>
    <span class="hljs-keyword">if</span> event_type == <span class="hljs-string">&#x27;on_tool_start&#x27;</span> <span class="hljs-keyword">and</span> event[<span class="hljs-string">&#x27;data&#x27;</span>]:
        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;开始调用工具查询&#x27;</span>, event[<span class="hljs-string">&#x27;data&#x27;</span>],<span class="hljs-string">&#x27;\n\n&#x27;</span>)
        <span class="hljs-keyword">pass</span>
    <span class="hljs-keyword">elif</span> event_type == <span class="hljs-string">&#x27;on_tool_end&#x27;</span> <span class="hljs-keyword">and</span> event[<span class="hljs-string">&#x27;data&#x27;</span>]:
        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;工具查询结束&#x27;</span>,event[<span class="hljs-string">&#x27;data&#x27;</span>],<span class="hljs-string">&#x27;\n\n&#x27;</span>)
        <span class="hljs-keyword">pass</span>
    <span class="hljs-keyword">elif</span> event_type == <span class="hljs-string">&#x27;on_chat_model_stream&#x27;</span>:
        <span class="hljs-comment"># print(&#x27;on_chat_model_stream事件------&gt;&#x27;,event[&quot;data&quot;][&quot;chunk&quot;].content,&#x27;\n\n&#x27;)</span>
        chunk_data = event[<span class="hljs-string">&quot;data&quot;</span>][<span class="hljs-string">&quot;chunk&quot;</span>].content <span class="hljs-comment"># 流式输出的内容</span>
        output_list.append(chunk_data)
        <span class="hljs-built_in">print</span>(chunk_data, end=<span class="hljs-string">&#x27;&#x27;</span>, flush=<span class="hljs-literal">True</span>)</code></pre></div>

<p>这里我们添加了对工具执行开始和结束事件的监听，这样用户可以看到后台工作流程。</p>
<h2 id="9-测试结果"><a href="#9-测试结果" class="headerlink" title="9. 测试结果"></a>9. 测试结果</h2><p>当运行代码时，整个过程如下：</p>
<ol>
<li>LLM分析用户问题”crawl4ai是什么？”</li>
<li>决定这需要专业知识，调用搜索工具获取相关链接</li>
<li>搜索工具返回关于crawl4ai的信息网页链接</li>
<li>网页抓取工具获取这些链接的具体内容</li>
<li>总结模型分析内容，生成一个全面的crawl4ai的解释</li>
</ol>
<p>复比单纯依赖搜索引擎摘要的回复更全面、更深入，因为它基于多个网页的完整内容，而不仅仅是搜索结果的摘要。</p>
<p>问题：</p>
<blockquote>
<p>crawl4ai 是什么？</p>
</blockquote>
<p>回答结果：</p>
<p>可以看到ai搜索工具调用结果返回的搜索到的链接是：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/2380440002">https://zhuanlan.zhihu.com/p/2380440002</a></p>
<p>这个页面的文章长这样：<br><img src="/img/blog/AI/langgraph/2025-04-12_22-36-58.png" srcset="/img/loading.gif" lazyload></p>
<p>使用crawl4ai爬出的结果：<br><img src="/img/blog/AI/langgraph/2025-04-12_23-16-16.png" srcset="/img/loading.gif" lazyload></p>
<blockquote>
<p>crawl4ai听起来像是一个团队或者项目的名字，但具体的含义或背景信息可能需要进一步的搜索来确定。让我帮您查找一下相关信息。</p>
<h3 id="Crawl4AI-简介"><a href="#Crawl4AI-简介" class="headerlink" title="Crawl4AI 简介"></a>Crawl4AI 简介</h3><p>Crawl4AI 是一个开源的 Python 库，主要用于简化网页爬取和提取信息。它旨在帮助用户高效地完成网页爬取任务，尤其适用于大语言模型（LLMs）和 AI 应用。Crawl4AI 可以作为 REST API 或 Python 库使用，支持异步操作，并提供了一系列强大的功能。</p>
<h3 id="主要特点"><a href="#主要特点" class="headerlink" title="主要特点"></a>主要特点</h3><ul>
<li><strong>免费且开源</strong>：Crawl4AI 是完全免费的，并且代码是开源的。</li>
<li><strong>高性能</strong>：其性能超越了许多付费服务。</li>
<li><strong>LLM 友好</strong>：输出格式包括 JSON、清理后的 HTML 和 Markdown，便于 LLM 处理。</li>
<li><strong>多 URL 爬取</strong>：支持同时爬取多个 URL。</li>
<li><strong>媒体和链接提取</strong>：可以提取所有媒体标签（图片、音频和视频）以及外部和内部链接。</li>
<li><strong>元数据提取</strong>：从页面中提取元数据。</li>
<li><strong>自定义功能</strong>：支持自定义身份验证、请求头和页面修改的钩子。</li>
<li><strong>用户代理和页面截屏</strong>：支持用户代理自定义和页面截屏。</li>
<li><strong>JavaScript 执行</strong>：在爬取前可以执行多个自定义 JavaScript。</li>
<li><strong>结构化输出</strong>：使用 JsonCssExtractionStrategy 生成结构化输出。</li>
<li><strong>多种分块策略</strong>：支持基于主题、正则表达式、句子等的分块策略。</li>
<li><strong>高级提取策略</strong>：包括余弦聚类、LLM 等。</li>
<li><strong>CSS 选择器</strong>：支持 CSS 选择器进行精确数据提取。</li>
<li><strong>指令/关键词优化</strong>：可以通过传递指令/关键词来优化提取。</li>
<li><strong>代理支持</strong>：支持代理以增强隐私和访问。</li>
<li><strong>会话管理</strong>：为复杂的多页面爬取场景管理会话。</li>
<li><strong>异步架构</strong>：提高性能和可扩展性。</li>
</ul>
<h3 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h3><p>要使用 Crawl4AI，需要安装一些依赖库和软件，包括 &gt; Python、pip、playwright 等。</p>
<h3 id="基础使用"><a href="#基础使用" class="headerlink" title="基础使用"></a>基础使用</h3><p>Crawl4AI 提供了简单的 API 来提取网页内容。例如，可&gt; 以使用 <code>AsyncWebCrawler</code> 类来爬取网页，并打印出提&gt; 取的 Markdown 内容。</p>
<h3 id="高级使用"><a href="#高级使用" class="headerlink" title="高级使用"></a>高级使用</h3><p>Crawl4AI 还支持更高级的功能，如执行 JavaScript 脚&gt; 本、使用 CSS 选择器进行数据提取等。</p>
<h3 id="结构化数据提取"><a href="#结构化数据提取" class="headerlink" title="结构化数据提取"></a>结构化数据提取</h3><p>Crawl4AI 的 JsonCssExtractionStrategy 功能允许从&gt; 网页中精确提取结构化数据，这对于从产品列表、新闻文&gt; 章或搜索结果等页面中提取数据非常有用。</p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>Crawl4AI 是一个功能强大的网页爬取和提取工具，适用&gt; 于各种爬取任务，特别是对于需要处理大量数据的 LLM &gt; 和 AI 应用。它提供了丰富的功能和灵活的配置选项，使&gt; 得用户可以轻松地完成复杂的爬 取任务。</p>
<p><strong>来源</strong>：</p>
<ul>
<li>[GitHub - unclecode/crawl4ai: ️ Crawl4AI: &gt; Open-source LLM Friendly Web Crawler &amp; &gt; Scrapper](<a target="_blank" rel="noopener" href="https://link.zhihu.com/?&gt;">https://link.zhihu.com/?&gt;</a> target=https%3A//github.com/unclecode/crawl4ai)</li>
<li>[Home - Crawl4AI Documentation](<a target="_blank" rel="noopener" href="https://link.&gt;/">https://link.&gt;</a> zhihu.com/?target=https%3A//crawl4ai.com/&gt; mkdocs/)</li>
</ul>
</blockquote>
<h3 id="以下是完整log："><a href="#以下是完整log：" class="headerlink" title="以下是完整log："></a>以下是完整log：</h3><div class="code-wrapper"><pre><code class="hljs taggerscript">开始流式生成回答...

crawl4ai听起来像是一个团队或者项目的名字，但具体的含义或背景信息可能需要进一步的搜索来确定。让我帮您查找一下相关信息。

搜索工具结果的完整输出------&gt; [&#123;&#x27;title&#x27;: &#x27;Crawl4AI：基于LLMs 的高效爬虫工具 - 知乎专栏&#x27;, &#x27;url&#x27;: &#x27;https://zhuanlan.zhihu.com/p/2380440002&#x27;, &#x27;content&#x27;: &#x27;Crawl4AI 是一个开源的Python 库，旨在简化网页爬取并提取有用的信息。Crawl4AI 的核心任务是使网页爬取和数据提取变得简单高效，特别是为大语言模型（LLMs）和AI 应用&#x27;, &#x27;score&#x27;: 0.6612456&#125;] 

开始调用工具查询 &#123;&#x27;input&#x27;: &#123;&#x27;query&#x27;: &#x27;crawl4ai 是什么&#x27;&#125;&#125; 


开始调用工具查询 &#123;&#x27;input&#x27;: &#123;&#125;&#125; 


工具查询结束 &#123;&#x27;output&#x27;: [&#123;&#x27;title&#x27;: &#x27;Crawl4AI：基于LLMs 的高效爬虫工具 - 知乎专栏&#x27;, &#x27;url&#x27;: &#x27;https://zhuanlan.zhihu.com/p/2380440002&#x27;, &#x27;content&#x27;: &#x27;Crawl4AI 是一个开源的Python 库，旨在简化网页爬取并提取有用的信息。Crawl4AI 的核心任务是使网页爬取和数据提取变得简单高效，特别是为大语言模型（LLMs）和AI 应用&#x27;, &#x27;score&#x27;: 0.6612456&#125;], &#x27;input&#x27;: None&#125; 


工具查询结束 &#123;&#x27;output&#x27;: [&#123;&#x27;title&#x27;: &#x27;Crawl4AI：基于LLMs 的高效爬虫工具 - 知乎专栏&#x27;, &#x27;url&#x27;: &#x27;https://zhuanlan.zhihu.com/p/2380440002&#x27;, &#x27;content&#x27;: &#x27;Crawl4AI 是一个开源的Python 库，旨在简化网页爬取并提取有用的信息。Crawl4AI 的核心任务是使网页爬取和数据提取变得简单高效，特别是为大语言模型（LLMs）和AI 应用&#x27;, &#x27;score&#x27;: 0.6612456&#125;], &#x27;input&#x27;: &#123;&#x27;query&#x27;: &#x27;crawl4ai 是什么&#x27;&#125;&#125;


开始调用工具查询 &#123;&#x27;input&#x27;: &#123;&#x27;query&#x27;: [&#x27;https://zhuanlan.zhihu.com/p/2380440002&#x27;]&#125;&#125;


crawl4ai_tool收到的完整输入------&gt; [&#x27;https://zhuanlan.zhihu.com/p/2380440002&#x27;]

urls------&gt; [&#x27;https://zhuanlan.zhihu.com/p/2380440002&#x27;]
[INIT].... → Crawl4AI 0.5.0.post4
[FETCH]... ↓ https://zhuanlan.zhihu.com/p/2380440002... | Status: True | Time: 2.50s
[SCRAPE].. ◆ https://zhuanlan.zhihu.com/p/2380440002... | Time: 0.102s
[COMPLETE] ● https://zhuanlan.zhihu.com/p/2380440002... | Status: True | Total: 2.62s
[OK] https://zhuanlan.zhihu.com/p/2380440002, length: 9849
所有结果已保存到文件: crawl_results_20250412_223529.md
工具查询结束 &#123;&#x27;output&#x27;: &#123;&#x27;result&#x27;: &#x27;[](https://www.zhihu.com)<span class="hljs-symbol">\n</span>首发于[LLMs app开发](https://www.zhihu.com/column/c_1345788827353407488)<span class="hljs-symbol">\n</span>切换模式<span class="hljs-symbol">\n</span>写文章<span class="hljs-symbol">\n</span>登录/注册<span class="hljs-symbol">\n</span><span class="hljs-symbol">\u</span>200b<span class="hljs-symbol">\n</span>目
录<span class="hljs-symbol">\n</span>## 简介和特点<span class="hljs-symbol">\n</span>Crawl4AI 是一个开源的 Python 库，旨在简化网页爬取并提取有用的信息。Crawl4AI 的核心任务是使网页爬取和数据提取变得简单高效，特别是为大语言模型（[LLMs](https://zhida.zhihu.com/search?content_id=249498630&amp;content_type=Article&amp;match_order=1&amp;q=LLMs&amp;zd_token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJ6aGlkYV9zZXJ2ZXIiLCJleHAiOjE3NDQ2NDEzNDksInEiOiJMTE1zIiwiemhpZGFfc291cmNlIjoiZW50aXR5IiwiY29udGVudF9pZCI6MjQ5NDk4NjMwLCJjb250ZW50X3R5cGUiOiJBcnRpY2xlIiwibWF0Y2hfb3JkZXIiOjEsInpkX3Rva2VuIjpudWxsfQ.kzXn27NE3N_uVFyvx7BVGTka8WVN6HqQ6xZItO8RUv0&amp;zhida_source=entity)）和 AI 应用提供支持。无论您是将其作为 REST API 还是 Python 库来使用，Crawl4AI 都提供了一个强大且灵活的解决方案，并且完全支持异步操作。<span class="hljs-symbol">\n</span>**特点如下：**<span class="hljs-symbol">\n</span>完全免费且开源<span class="hljs-symbol">\n</span>极快的性能，超越许多付费服务<span class="hljs-symbol">\n</span>LLM 友好的输出格式（JSON，清理后的 HTML，Markdown）<span class="hljs-symbol">\n</span>支持同时爬取多个 URL<span class="hljs-symbol">\n</span>提取并返回所有媒体标签（图片、音频和视频）<span class="hljs-symbol">\n</span>提取所有外部和内部链接<span class="hljs-symbol">\n</span>从页面中提取元数据<span class="hljs-symbol">\n</span>支持在爬取前的自定义身份验证、请求头和页面修改的钩子<span class="hljs-symbol">\n</span>️ 用户代理自定义<span class="hljs-symbol">\n</span>️ 为页面截屏<span class="hljs-symbol">\n</span>在爬取前执行多个自定义 JavaScript<span class="hljs-symbol">\n</span> n使用 JsonCssExtractionStrategy 生成结构化输出，无需 LLM<span class="hljs-symbol">\n</span>多种分块策略：基于主题、正则表达式、句子等<span class="hljs-symbol">\n</span>高级提取策略：余弦聚类、LLM 等<span class="hljs-symbol">\n</span>支持 CSS 选择器进行精确数据提取<span class="hljs-symbol">\n</span>传递指令/关键词以优化提取<span class="hljs-symbol">\n</span>支持代理以增强隐私和访问<span class="hljs-symbol">\n</span>为复杂的多页面爬取场景管理会话<span class="hljs-symbol">\n</span>异步架构，提高性能和可扩展性<span class="hljs-symbol">\n</span>## 环境准备<span class="hljs-symbol">\n</span>```<span class="hljs-symbol">\n</span>!sudo apt-get update &amp;&amp; sudo apt-get install -y libwoff1 libopus0 libwebp6 libwebpdemux2 libenchant1c2a libgudev-1.0-0 libsecret-1-0 libhyphen0 libgdk-pixbuf2.0-0 libegl1 libnotify4 libxslt1.1 libevent-2.1-7 libgles2 libvpx6 libxcomposite1 libatk1.0-0 libatk-bridge2.0-0 libepoxy0 libgtk-3-0 libharfbuzz-icu0<span class="hljs-symbol">\n</span>!pip install crawl4ai<span class="hljs-symbol">\n</span>!pip install nest-asyncio<span class="hljs-symbol">\n</span>!playwright install<span class="hljs-symbol">\n</span>import asyncio<span class="hljs-symbol">\n</span>import nest_asyncio<span class="hljs-symbol">\n</span>from crawl4ai import AsyncWebCrawler<span class="hljs-symbol">\n</span>from crawl4ai.extraction_strategy import JsonCssExtractionStrategy, LLMExtractionStrategy<span class="hljs-symbol">\n</span>import json<span class="hljs-symbol">\n</span>import time<span class="hljs-symbol">\n</span>from pydantic import BaseModel, Field<span class="hljs-symbol">\n</span>nest_asyncio.apply()<span class="hljs-symbol">\n</span>```<span class="hljs-symbol">\n</span><span class="hljs-symbol">\n</span>## 基础使用：提取网页内容<span class="hljs-symbol">\n</span>```<span class="hljs-symbol">\n</span>async def simple_crawl():<span class="hljs-symbol">\n</span>  async with AsyncWebCrawler(verbose=True) as crawler:<span class="hljs-symbol">\n</span>    result = await crawler.arun(url=&quot;https://www.nbcnews.com/business&quot;)<span class="hljs-symbol">\n</span>    print()<span class="hljs-symbol">\n</span>    print(len(result.markdown))<span class="hljs-symbol">\n</span>    print(result.markdown[:500])<span class="hljs-symbol">\n</span>await simple_crawl()<span class="hljs-symbol">\n</span>```<span class="hljs-symbol">\n</span><span class="hljs-symbol">\n</span>爬取结果：<span class="hljs-symbol">\n</span>## 高级使用：JS 脚本执行和CSS选择器的使用<span class="hljs-symbol">\n</span>```<span class="hljs-symbol">\n</span>async def js_and_css():<span class="hljs-symbol">\n</span>  print(&quot;<span class="hljs-symbol">\\</span>n--- Executing JavaScript and Using CSS Selectors ---&quot;)<span class="hljs-symbol">\n</span>  # New code to handle the wait_for parameter<span class="hljs-symbol">\n</span>  wait_for = &quot;&quot;&quot;() =&gt; &#123;<span class="hljs-symbol">\n</span>    return Array.from(document.querySelectorAll(<span class="hljs-symbol">\&#x27;</span>article.tease-card<span class="hljs-symbol">\&#x27;</span>)).length &gt; 10;<span class="hljs-symbol">\n</span>  &#125;&quot;&quot;&quot;<span class="hljs-symbol">\n</span>  # wait_for can be also just a css selector<span class="hljs-symbol">\n</span>  # wait_for = &quot;article.tease-card:nth-child(10)&quot;<span class="hljs-symbol">\n</span>  async with AsyncWebCrawler(verbose=True) as crawler:<span class="hljs-symbol">\n</span>    js_code = [<span class="hljs-symbol">\n</span>      &quot;const loadMoreButton = Array.from(document.querySelectorAll(<span class="hljs-symbol">\&#x27;</span>button<span class="hljs-symbol">\&#x27;</span>)).find(button =&gt; button.textContent.includes(<span class="hljs-symbol">\&#x27;</span>Load More<span class="hljs-symbol">\&#x27;</span>)); loadMoreButton &amp;&amp; loadMoreButton.click();&quot;<span class="hljs-symbol">\n</span>    ]<span class="hljs-symbol">\n</span>    result = await crawler.arun(<span class="hljs-symbol">\n</span>      url=&quot;https://www.nbcnews.com/business&quot;,<span class="hljs-symbol">\n</span>      js_code=js_code,<span class="hljs-symbol">\n</span>      css_selector=&quot;article.tease-card&quot;,<span class="hljs-symbol">\n</span>      # wait_for=wait_for,<span class="hljs-symbol">\n</span>      bypass_cache=True,<span class="hljs-symbol">\n</span>    )<span class="hljs-symbol">\n</span>    print(result.markdown[:500]) # Print first 500 characters<span class="hljs-symbol">\n</span>await js_and_css()<span class="hljs-symbol">\n</span>```<span class="hljs-symbol">\n</span><span class="hljs-symbol">\n</span>## gpt-4o 结构化数据提取<span class="hljs-symbol">\n</span>```<span class="hljs-symbol">\n</span>import os<span class="hljs-symbol">\n</span>from google.colab import userdata<span class="hljs-symbol">\n</span>#os.environ[<span class="hljs-symbol">\&#x27;</span>OPENAI_API_KEY<span class="hljs-symbol">\&#x27;</span>] = userdata.get(<span class="hljs-symbol">\&#x27;</span>OPENAI_API_KEY<span class="hljs-symbol">\&#x27;</span>)<span class="hljs-symbol">\n</span>os.environ[<span class="hljs-symbol">\&#x27;</span>OPENAI_API_KEY<span class="hljs-symbol">\&#x27;</span>] = &quot;sk-xxxx&quot; ## 请输入你个人的 api key<span class="hljs-symbol">\n</span> <span class="hljs-symbol">\n</span>class OpenAIModelFee(BaseModel):<span class="hljs-symbol">\n</span>  model_name: str = Field(..., description=&quot;Name of the OpenAI model.&quot;)<span class="hljs-symbol">\n</span>  input_fee: str = Field(..., description=&quot;Fee for input token for the OpenAI model.&quot;)<span class="hljs-symbol">\n</span>  output_fee: str = Field(..., description=&quot;Fee for output token for the OpenAI model.&quot;)<span class="hljs-symbol">\n</span>async def extract_openai_fees():<span class="hljs-symbol">\n</span>  async with AsyncWebCrawler(verbose=True) as crawler:<span class="hljs-symbol">\n</span>    result = await crawler.arun(<span class="hljs-symbol">\n</span>      url=<span class="hljs-symbol">\&#x27;</span>https://openai.com/api/pricing/<span class="hljs-symbol">\&#x27;</span>,<span class="hljs-symbol">\n</span>      word_count_threshold=1,<span class="hljs-symbol">\n</span>      extraction_strategy=LLMExtractionStrategy(<span class="hljs-symbol">\n</span>        provider=&quot;openai/gpt-4o-2024-08-06&quot;, api_token=os.getenv(<span class="hljs-symbol">\&#x27;</span>OPENAI_API_KEY<span class="hljs-symbol">\&#x27;</span>),<span class="hljs-symbol">\n</span>        schema=OpenAIModelFee.schema(),<span class="hljs-symbol">\n</span>        extraction_type=&quot;schema&quot;,<span class="hljs-symbol">\n</span>        instruction=&quot;&quot;&quot;From the crawled content, extract all mentioned model names along with their fees for input and output tokens.<span class="hljs-symbol">\n</span>        Do not miss any models in the entire content. One extracted model JSON format should look like this:<span class="hljs-symbol">\n</span>        &#123;&quot;model_name&quot;: &quot;GPT-4&quot;, &quot;input_fee&quot;: &quot;US$10.00 / 1M tokens&quot;, &quot;output_fee&quot;: &quot;US$30.00 / 1M tokens&quot;&#125;.&quot;&quot;&quot;<span class="hljs-symbol">\n</span>      ),<span class="hljs-symbol">\n</span>      bypass_cache=True,<span class="hljs-symbol">\n</span>    )<span class="hljs-symbol">\n</span>    print(len(result.extracted_content))<span class="hljs-symbol">\n</span>    print(result.extracted_content)<span class="hljs-symbol">\n</span># Uncomment the following line to run the OpenAI extraction example<span class="hljs-symbol">\n</span>await extract_openai_fees()<span class="hljs-symbol">\n</span>```<span class="hljs-symbol">\n</span><span class="hljs-symbol">\n</span>返回的结果：<span class="hljs-symbol">\n</span>## JS 脚本执行+多页内容爬取<span class="hljs-symbol">\n</span>下面的案例展示了 Crawl4AI 处理复杂爬取场景的能力，特别是从 GitHub 仓库的多个页面中提取提交记录。这里的挑战在于，点击&quot;下一页&quot;按钮并不会加载新页面，而是使用异步 JavaScript 来更新内容。这在现代网页爬取中是一个常见的难题。<span class="hljs-symbol">\n</span>为了解决这个问题，我们使用了 Crawl4AI 的自定义 JavaScript 执行功能，模拟点击&quot;下一页&quot;按钮 ，并实现了一个自定义钩子来检测新数据是否加载。我们的策略是比较点击&quot;下一页&quot;前后第一个提交记录的文本，等待其变化，以确认新数据已呈现。这展示了 Crawl4AI 在处理动态内容时的灵活性， 以及在面对最具挑战性的爬取任务时实现自定义逻辑的能力。<span class="hljs-symbol">\n</span>```<span class="hljs-symbol">\n</span>import re<span class="hljs-symbol">\n</span>from bs4 import BeautifulSoup<span class="hljs-symbol">\n</span>async def crawl_dynamic_content_pages_method_3():<span class="hljs-symbol">\n</span>  print(&quot;<span class="hljs-symbol">\\</span>n--- Advanced Multi-Page Crawling with JavaScript Execution using `wait_for` ---&quot;)<span class="hljs-symbol">\n</span>  async with AsyncWebCrawler(verbose=True) as crawler:<span class="hljs-symbol">\n</span>    url = &quot;https://github.com/microsoft/TypeScript/commits/main&quot;<span class="hljs-symbol">\n</span>    session_id = &quot;typescript_commits_session&quot;<span class="hljs-symbol">\n</span>    all_commits = []<span class="hljs-symbol">\n</span>    js_next_page = &quot;&quot;&quot;<span class="hljs-symbol">\n</span>    const commits = document.querySelectorAll(<span class="hljs-symbol">\&#x27;</span>li.Box-sc-g0xbh4-0 h4<span class="hljs-symbol">\&#x27;</span>);<span class="hljs-symbol">\n</span>    if (commits.length &gt; 0) &#123;<span class="hljs-symbol">\n</span>      window.firstCommit = commits[0].textContent.trim();<span class="hljs-symbol">\n</span>    &#125;<span class="hljs-symbol">\n</span>    const button = document.querySelector(<span class="hljs-symbol">\&#x27;</span>a[data-testid=&quot;pagination-next-button&quot;]<span class="hljs-symbol">\&#x27;</span>);<span class="hljs-symbol">\n</span>    if (button) button.click();<span class="hljs-symbol">\n</span>    &quot;&quot;&quot;<span class="hljs-symbol">\n</span>    wait_for = &quot;&quot;&quot;() =&gt; &#123;<span class="hljs-symbol">\n</span>      const commits = document.querySelectorAll(<span class="hljs-symbol">\&#x27;</span>li.Box-sc-g0xbh4-0 h4<span class="hljs-symbol">\&#x27;</span>);<span class="hljs-symbol">\n</span>      if (commits.length === 0) return false;<span class="hljs-symbol">\n</span>      const firstCommit = commits[0].textContent.trim();<span class="hljs-symbol">\n</span>      return firstCommit !== window.firstCommit;<span class="hljs-symbol">\n</span>    &#125;&quot;&quot;&quot;<span class="hljs-symbol">\n</span>    schema = &#123;<span class="hljs-symbol">\n</span>      &quot;name&quot;: &quot;Commit Extractor&quot;,<span class="hljs-symbol">\n</span>      &quot;baseSelector&quot;: &quot;li.Box-sc-g0xbh4-0&quot;,<span class="hljs-symbol">\n</span>      &quot;fields&quot;: [<span class="hljs-symbol">\n</span>        &#123;<span class="hljs-symbol">\n</span>          &quot;name&quot;: &quot;title&quot;,<span class="hljs-symbol">\n</span>          &quot;selector&quot;: &quot;h4.markdown-title&quot;,<span class="hljs-symbol">\n</span>          &quot;type&quot;: &quot;text&quot;,<span class="hljs-symbol">\n</span>          &quot;transform&quot;: &quot;strip&quot;,<span class="hljs-symbol">\n</span>        &#125;,<span class="hljs-symbol">\n</span>      ],<span class="hljs-symbol">\n</span>    &#125;<span class="hljs-symbol">\n</span>    extraction_strategy = JsonCssExtractionStrategy(schema, verbose=True)<span class="hljs-symbol">\n</span>    for page in range(3): # Crawl 3 pages<span class="hljs-symbol">\n</span>      result = await crawler.arun(<span class="hljs-symbol">\n</span>        url=url,<span class="hljs-symbol">\n</span>        session_id=session_id,<span class="hljs-symbol">\n</span>        css_selector=&quot;li.Box-sc-g0xbh4-0&quot;,<span class="hljs-symbol">\n</span>        extraction_strategy=extraction_strategy,<span class="hljs-symbol">\n</span>        js_code=js_next_page if page &gt; 0 else None,<span class="hljs-symbol">\n</span>        wait_for=wait_for if page &gt; 0 else None,<span class="hljs-symbol">\n</span>        js_only=page &gt; 0,<span class="hljs-symbol">\n</span>        bypass_cache=True,<span class="hljs-symbol">\n</span>        headless=False,<span class="hljs-symbol">\n</span>      )<span class="hljs-symbol">\n</span>      assert result.success, f&quot;Failed to crawl page &#123;page + 1&#125;&quot;<span class="hljs-symbol">\n</span>      commits = json.loads(result.extracted_content)<span class="hljs-symbol">\n</span>      all_commits.extend(commits)<span class="hljs-symbol">\n</span>      print(f&quot;Page &#123;page + 1&#125;: Found &#123;len(commits)&#125; commits&quot;)<span class="hljs-symbol">\n</span>    await crawler.crawler_strategy.kill_session(session_id)<span class="hljs-symbol">\n</span>    print(f&quot;Successfully crawled &#123;len(all_commits)&#125; commits across 3 pages&quot;)<span class="hljs-symbol">\n</span>await crawl_dynamic_content_pages_method_3()<span class="hljs-symbol">\n</span>```<span class="hljs-symbol">\n</span><span class="hljs-symbol">\n</span>爬取结果：<span class="hljs-symbol">\n</span>## JsonCss 提取和快速结构化输出<span class="hljs-symbol">\n</span>JsonCssExtractionStrategy 是 Crawl4AI 的一个强大功能，允许从网页中精确提取结构化数据。其工作原理如下：<span class="hljs-symbol">\n</span>  1. 你定义一个描述所需数据提取模式的模式（schema）。<span class="hljs-symbol">\n</span>  2. 该模式包括一个基础选择器，用于标识页面上重复的 元素。<span class="hljs-symbol">\n</span>  3. 在模式中，你可以定义字段，每个字段都有自己的选择器和类型。<span class="hljs-symbol">\n</span>  4. 这些字段选择器将在每个基础选择器元素的上下文中应用。<span class="hljs-symbol">\n</span>  5. 该策略支持嵌套结构、列表中的列表和各种数据类型。<span class="hljs-symbol">\n</span>  6. 你甚至可以包含计算字段来进行更复杂的数据处理。<span class="hljs-symbol">\n</span><span class="hljs-symbol">\n</span><span class="hljs-symbol">\n</span>这种方法允许高度灵活和精确的数据提取，将半结构化的网页内容转化为干净、结构化的 JSON 数据。它在从产品列表、新闻文章或搜索结果等页面中提取一致数据模式时尤其有用。<span class="hljs-symbol">\n</span>```<span class="hljs-symbol">\n</span>async def extract_news_teasers():<span class="hljs-symbol">\n</span>  schema = &#123;<span class="hljs-symbol">\n</span>    &quot;name&quot;: &quot;News Teaser Extractor&quot;,<span class="hljs-symbol">\n</span>    &quot;baseSelector&quot;: &quot;.wide-tease-item__wrapper&quot;,<span class="hljs-symbol">\n</span>    &quot;fields&quot;: [<span class="hljs-symbol">\n</span>      &#123;<span class="hljs-symbol">\n</span>        &quot;name&quot;: &quot;category&quot;,<span class="hljs-symbol">\n</span>        &quot;selector&quot;: &quot;.unibrow span[data-testid=<span class="hljs-symbol">\&#x27;</span>unibrow-text<span class="hljs-symbol">\&#x27;</span>]&quot;,<span class="hljs-symbol">\n</span>        &quot;type&quot;: &quot;text&quot;,<span class="hljs-symbol">\n</span>      &#125;,<span class="hljs-symbol">\n</span>      &#123;<span class="hljs-symbol">\n</span>        &quot;name&quot;: &quot;headline&quot;,<span class="hljs-symbol">\n</span>        &quot;selector&quot;: &quot;.wide-tease-item__headline&quot;,<span class="hljs-symbol">\n</span>        &quot;type&quot;: &quot;text&quot;,<span class="hljs-symbol">\n</span>      &#125;,<span class="hljs-symbol">\n</span>      &#123;<span class="hljs-symbol">\n</span>        &quot;name&quot;: &quot;summary&quot;,<span class="hljs-symbol">\n</span>        &quot;selector&quot;: &quot;.wide-tease-item__description&quot;,<span class="hljs-symbol">\n</span>        &quot;type&quot;: &quot;text&quot;,<span class="hljs-symbol">\n</span>      &#125;,<span class="hljs-symbol">\n</span>      &#123;<span class="hljs-symbol">\n</span>        &quot;name&quot;: &quot;time&quot;,<span class="hljs-symbol">\n</span>        &quot;selector&quot;: &quot;[data-testid=<span class="hljs-symbol">\&#x27;</span>wide-tease-date<span class="hljs-symbol">\&#x27;</span>]&quot;,<span class="hljs-symbol">\n</span>        &quot;type&quot;: &quot;text&quot;,<span class="hljs-symbol">\n</span>      &#125;,<span class="hljs-symbol">\n</span>      &#123;<span class="hljs-symbol">\n</span>        &quot;name&quot;: &quot;image&quot;,<span class="hljs-symbol">\n</span>        &quot;type&quot;: &quot;nested&quot;,<span class="hljs-symbol">\n</span>        &quot;selector&quot;: &quot;picture.teasePicture img&quot;,<span class="hljs-symbol">\n</span>        &quot;fields&quot;: [<span class="hljs-symbol">\n</span>          &#123;&quot;name&quot;: &quot;src&quot;, &quot;type&quot;: &quot;attribute&quot;, &quot;attribute&quot;: &quot;src&quot;&#125;,<span class="hljs-symbol">\n</span>          &#123;&quot;name&quot;: &quot;alt&quot;, &quot;type&quot;: &quot;attribute&quot;, &quot;attribute&quot;: &quot;alt&quot;&#125;,<span class="hljs-symbol">\n</span>        ],<span class="hljs-symbol">\n</span>      &#125;,<span class="hljs-symbol">\n</span>      &#123;<span class="hljs-symbol">\n</span>        &quot;name&quot;: &quot;link&quot;,<span class="hljs-symbol">\n</span>        &quot;selector&quot;: &quot;a[href]&quot;,<span class="hljs-symbol">\n</span>        &quot;type&quot;: &quot;attribute&quot;,<span class="hljs-symbol">\n</span>        &quot;attribute&quot;: &quot;href&quot;,<span class="hljs-symbol">\n</span>      &#125;,<span class="hljs-symbol">\n</span>    ],<span class="hljs-symbol">\n</span>  &#125;<span class="hljs-symbol">\n</span>  extraction_strategy = JsonCssExtractionStrategy(schema, verbose=True)<span class="hljs-symbol">\n</span>  async with AsyncWebCrawler(verbose=True) as crawler:<span class="hljs-symbol">\n</span>    result = await crawler.arun(<span class="hljs-symbol">\n</span>      url=&quot;https://www.nbcnews.com/business&quot;,<span class="hljs-symbol">\n</span>      extraction_strategy=extraction_strategy,<span class="hljs-symbol">\n</span>      bypass_cache=True,<span class="hljs-symbol">\n</span>    )<span class="hljs-symbol">\n</span>    assert result.success, &quot;Failed to crawl the page&quot;<span class="hljs-symbol">\n</span>    news_teasers = json.loads(result.extracted_content)<span class="hljs-symbol">\n</span>    print(f&quot;Successfully extracted &#123;len(news_teasers)&#125; news teasers&quot;)<span class="hljs-symbol">\n</span>    print(json.dumps(news_teasers[0], indent=2))<span class="hljs-symbol">\n</span>await extract_news_teasers()<span class="hljs-symbol">\n</span>```<span class="hljs-symbol">\n</span><span class="hljs-symbol">\n</span>结果如下：<span class="hljs-symbol">\n</span>来源：[GitHub - unclecode/crawl4ai: ️ Crawl4AI: Open-source LLM Friendly Web Crawler &amp; Scrapper](https://link.zhihu.com/?target=https<span class="hljs-variable">%3A//github.com/unclecode/crawl4ai)\n官网：[Home - Crawl4AI Documentatiion](https://link.zhihu.com/?target=https%</span>3A//crawl4ai.com/mkdocs/)<span class="hljs-symbol">\n</span>编辑于 2024-10-22 07:20・美国<span class="hljs-symbol">\n</span>[大模型](https://www.zhihu.com/topic/25402720)<span class="hljs-symbol">\n</span>[爬虫](https://www.zhihu.com/topic/20049326)<span class="hljs-symbol">\n</span>[AI](https://www.zhihu.com/topic/19588023)<span class="hljs-symbol">\n</span><span class="hljs-symbol">\u</span>200b赞同 19<span class="hljs-symbol">\u</span>200b<span class="hljs-symbol">\u</span>200b10 条评论<span class="hljs-symbol">\n</span><span class="hljs-symbol">\u</span>200b分享<span class="hljs-symbol">\n</span><span class="hljs-symbol">\u</span>200b喜欢<span class="hljs-symbol">\u</span>200b收藏<span class="hljs-symbol">\u</span>200b申请转载<span class="hljs-symbol">\n</span><span class="hljs-symbol">\u</span>200b<span class="hljs-symbol">\n</span>暂无评论<span class="hljs-symbol">\n</span>### 推荐阅读<span class="hljs-symbol">\n</span># [【Python】爬虫篇 Selenium运用你熟练到了什么程度？奔跑的蜗牛](https://zhuanlan.zhihu.com/p/441080010)# [Python爬虫——Selenium基础教程——准备苏小菁在编...发表于苏小菁在编...](https://zhuanlan.zhihu.com/p/137710454)# [别上来就爬，写爬虫也有模式和套路图灵君](https://zhuanlan.zhihu.com/p/62863150)# [【Python爬虫奇淫技巧】用pandas库read_html函数一行代码搞定 爬虫！马哥pyt...发表于马哥Pyt...](https://zhuanlan.zhihu.com/p/445464339)<span class="hljs-symbol">\n</span><span class="hljs-symbol">\n</span>_想来知乎工作？请发送邮件到 jobs@zhihu.com_<span class="hljs-symbol">\n</span>打开知乎App<span class="hljs-symbol">\n</span>在「我的页」右上角打开扫一扫<span class="hljs-symbol">\n</span>其他扫码方式：微信<span class="hljs-symbol">\n</span>下载知乎App<span class="hljs-symbol">\n</span>[开通机构号](https://zhuanlan.zhihu.com/org/signup)<span class="hljs-symbol">\n</span>无障碍模式<span class="hljs-symbol">\n</span>其他方式登录<span class="hljs-symbol">\n</span>未注册手机验证后自动登录，注册即代表同意[《知乎协议》](https://www.zhihu.com/term/zhihu-terms)[《隐私保护指引》](https://www.zhihu.com/term/privacy)<span class="hljs-symbol">\n</span>扫码下载知乎 App<span class="hljs-symbol">\n</span>关闭二维码<span class="hljs-symbol">\n</span><span class="hljs-symbol">\n</span><span class="hljs-symbol">\n</span>&#x27;&#125;, &#x27;input&#x27;: &#123;&#x27;query&#x27;: [&#x27;https://zhuanlan.zhihu.com/p/2380440002&#x27;]&#125;&#125;  



### Crawl4AI 简介

Crawl4AI 是一个开源的 Python 库，主要用于简化网页爬取和提取信息。它旨在帮助用户高效地完成网页爬取任务，尤其适用于大语言模型（LLMs）和 AI 应用。Crawl4AI 可以作为 REST API 或 Python 库使用，支持异步操作，并提供了一系列强大的功能。

### 主要特点

- **免费且开源**：Crawl4AI 是完全免费的，并且代码是开源的。
- **高性能**：其性能超越了许多付费服务。
- **LLM 友好**：输出格式包括 JSON、清理后的 HTML 和 Markdown，便于 LLM 处理。
- **多 URL 爬取**：支持同时爬取多个 URL。
- **媒体和链接提取**：可以提取所有媒体标签（图片、音频和视频）以及外部和内部链接。
- **元数据提取**：从页面中提取元数据。
- **自定义功能**：支持自定义身份验证、请求头和页面修改的钩子。
- **用户代理和页面截屏**：支持用户代理自定义和页面截屏。
- **JavaScript 执行**：在爬取前可以执行多个自定义 JavaScript。
- **结构化输出**：使用 JsonCssExtractionStrategy 生成结构化输出。
- **多种分块策略**：支持基于主题、正则表达式、句子等的分块策略。
- **高级提取策略**：包括余弦聚类、LLM 等。
- **CSS 选择器**：支持 CSS 选择器进行精确数据提取。
- **指令/关键词优化**：可以通过传递指令/关键词来优化提取。
- **代理支持**：支持代理以增强隐私和访问。
- **会话管理**：为复杂的多页面爬取场景管理会话。
- **异步架构**：提高性能和可扩展性。

### 环境准备

要使用 Crawl4AI，需要安装一些依赖库和软件，包括 Python、pip、playwright 等。

### 基础使用

Crawl4AI 提供了简单的 API 来提取网页内容。例如，可以使用 `AsyncWebCrawler` 类来爬取网页，并打印出提取的 Markdown 内容。

### 高级使用

Crawl4AI 还支持更高级的功能，如执行 JavaScript 脚本、使用 CSS 选择器进行数据提取等。

### 结构化数据提取

Crawl4AI 的 JsonCssExtractionStrategy 功能允许从网页中精确提取结构化数据，这对于从产品列表、新闻文章或搜索结果等页面中提取数据非常有用。

### 总结

Crawl4AI 是一个功能强大的网页爬取和提取工具，适用于各种爬取任务，特别是对于需要处理大量数据的 LLM 和 AI 应用。它提供了丰富的功能和灵活的配置选项，使得用户可以轻松地完成复杂的爬 取任务。

**来源**：
- [GitHub - unclecode/crawl4ai: ️ Crawl4AI: Open-source LLM Friendly Web Crawler &amp; Scrapper](https://link.zhihu.com/?target=https<span class="hljs-variable">%3A//github.com/unclecode/crawl4ai)</span>
<span class="hljs-variable">- [Home - Crawl4AI Documentation](https://link.zhihu.com/?target=https%</span>3A//crawl4ai.com/mkdocs/)


************************************************************************************************************************
生成完成！
 crawl4ai听起来像是一个团队或者项目的名字，但具体的含义或背景信息可能需要进一步的搜索来确定。让我帮您查找一下相关信息。


### Crawl4AI 简介

Crawl4AI 是一个开源的 Python 库，主要用于简化网页爬取和提取信息。它旨在帮助用户高效地完成网页爬取任务，尤其适用于大语言模型（LLMs）和 AI 应用。Crawl4AI 可以作为 REST API 或 Python 库使用，支持异步操作，并提供了一系列强大的功能。

### 主要特点

- **免费且开源**：Crawl4AI 是完全免费的，并且代码是开源的。
- **高性能**：其性能超越了许多付费服务。
- **LLM 友好**：输出格式包括 JSON、清理后的 HTML 和 Markdown，便于 LLM 处理。
- **多 URL 爬取**：支持同时爬取多个 URL。
- **媒体和链接提取**：可以提取所有媒体标签（图片、音频和视频）以及外部和内部链接。
- **元数据提取**：从页面中提取元数据。
- **自定义功能**：支持自定义身份验证、请求头和页面修改的钩子。
- **用户代理和页面截屏**：支持用户代理自定义和页面截屏。
- **JavaScript 执行**：在爬取前可以执行多个自定义 JavaScript。
- **结构化输出**：使用 JsonCssExtractionStrategy 生成结构化输出。
- **多种分块策略**：支持基于主题、正则表达式、句子等的分块策略。
- **高级提取策略**：包括余弦聚类、LLM 等。
- **CSS 选择器**：支持 CSS 选择器进行精确数据提取。
- **指令/关键词优化**：可以通过传递指令/关键词来优化提取。
- **代理支持**：支持代理以增强隐私和访问。
- **会话管理**：为复杂的多页面爬取场景管理会话。
- **异步架构**：提高性能和可扩展性。

### 环境准备

要使用 Crawl4AI，需要安装一些依赖库和软件，包括 Python、pip、playwright 等。

### 基础使用

Crawl4AI 提供了简单的 API 来提取网页内容。例如，可以使用 `AsyncWebCrawler` 类来爬取网页，并打印出提取的 Markdown 内容。

### 高级使用

Crawl4AI 还支持更高级的功能，如执行 JavaScript 脚本、使用 CSS 选择器进行数据提取等。

### 结构化数据提取

Crawl4AI 的 JsonCssExtractionStrategy 功能允许从网页中精确提取结构化数据，这对于从产品列表、新闻文章或搜索结果等页面中提取数据非常有用。

### 总结

Crawl4AI 是一个功能强大的网页爬取和提取工具，适用于各种爬取任务，特别是对于需要处理大量数据的 LLM 和 AI 应用。它提供了丰富的功能和灵活的配置选项，使得用户可以轻松地完成复杂的爬 取任务。

**来源**：
- [GitHub - unclecode/crawl4ai: ️ Crawl4AI: Open-source LLM Friendly Web Crawler &amp; Scrapper](https://link.zhihu.com/?target=https<span class="hljs-variable">%3A//github.com/unclecode/crawl4ai)</span>
<span class="hljs-variable">- [Home - Crawl4AI Documentation](https://link.zhihu.com/?target=https%</span>3A//crawl4ai.com/mkdocs/)


************************************************************************************************************************</code></pre></div>

<hr>
<blockquote>
<p>这里需要说明一下，如果问的是一些比如2024年AI发展报告，搜索工具会返回一些.pdf结尾的在线pdf页面，这种的话目前crawl4ai是无法爬取的，不过在GitHub上以看到有人提了这个问题，也回复了后续会更新相关功能，所以这里只是简单通过pormpt做了一些处理，比如如果爬取工具没有返回内容就直接将pdf的链接返回出来。</p>
</blockquote>
<hr>
<p>以下是完整代码：</p>
<div class="code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">from</span> datetime <span class="hljs-keyword">import</span> datetime
<span class="hljs-keyword">import</span> os
<span class="hljs-keyword">import</span> sys
<span class="hljs-keyword">from</span> dotenv <span class="hljs-keyword">import</span> load_dotenv
load_dotenv()
<span class="hljs-keyword">import</span> asyncio
<span class="hljs-keyword">from</span> langchain_openai <span class="hljs-keyword">import</span> ChatOpenAI
<span class="hljs-keyword">from</span> langchain_community.chat_models <span class="hljs-keyword">import</span> QianfanChatEndpoint
<span class="hljs-keyword">from</span> langchain_community.tools.tavily_search <span class="hljs-keyword">import</span> TavilySearchResults
<span class="hljs-keyword">from</span> langchain_community.tools.ddg_search.tool <span class="hljs-keyword">import</span> DuckDuckGoSearchResults
<span class="hljs-keyword">from</span> langchain_core.messages <span class="hljs-keyword">import</span> BaseMessage, HumanMessage, AIMessage, SystemMessage, ToolMessage
<span class="hljs-keyword">from</span> langgraph.graph <span class="hljs-keyword">import</span> StateGraph, START, END, MessagesState
<span class="hljs-keyword">from</span> langchain_core.utils.function_calling <span class="hljs-keyword">import</span> convert_to_openai_function
<span class="hljs-keyword">from</span> langchain_core.runnables.graph <span class="hljs-keyword">import</span> MermaidDrawMethod
<span class="hljs-keyword">from</span> langchain_core.messages <span class="hljs-keyword">import</span> ToolMessage
<span class="hljs-keyword">from</span> langchain_core.tools <span class="hljs-keyword">import</span> tool

<span class="hljs-comment"># 添加项目根目录到Python路径</span>
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
<span class="hljs-keyword">from</span> crawl_tool <span class="hljs-keyword">import</span> quick_crawl_tool

<span class="hljs-comment"># 创建图构建器</span>
graph_builder = StateGraph(MessagesState)

os.environ[<span class="hljs-string">&#x27;TAVILY_API_KEY&#x27;</span>] = os.getenv(<span class="hljs-string">&#x27;TAVILY_API_KEY&#x27;</span>, <span class="hljs-string">&#x27;&#x27;</span>)

<span class="hljs-comment"># 创建工具</span>
<span class="hljs-meta">@tool</span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">search_tool</span>(<span class="hljs-params">query: <span class="hljs-built_in">str</span></span>):</span>
    <span class="hljs-string">&quot;&quot;&quot;用于浏览网络进行搜索。&quot;&quot;&quot;</span>
    search_tool = TavilySearchResults(max_results=<span class="hljs-number">1</span>)
    <span class="hljs-comment"># search_tool = DuckDuckGoSearchResults(max_results=1, output_format=&quot;list&quot;) # output_format=&quot;list&quot;</span>
    <span class="hljs-keyword">return</span> search_tool.invoke(query)

<span class="hljs-meta">@tool</span>
<span class="hljs-keyword">async</span> <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">crawl4ai_tool</span>(<span class="hljs-params">query: <span class="hljs-built_in">list</span>[<span class="hljs-built_in">str</span>]</span>):</span>
    <span class="hljs-string">&quot;&quot;&quot;用于爬取网页内容。接收URL列表，返回对应网页的内容。&quot;&quot;&quot;</span>
    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;crawl4ai_tool收到的完整输入------&gt;&#x27;</span>,query,<span class="hljs-string">&#x27;\n&#x27;</span>)
    urls = query
    result = <span class="hljs-keyword">await</span> quick_crawl_tool(urls)
    <span class="hljs-keyword">return</span> &#123;<span class="hljs-string">&quot;result&quot;</span>: result&#125;

tools = [search_tool, crawl4ai_tool]

<span class="hljs-comment"># 创建llm，需要支持FunctionCalling的模型</span>
llm = ChatOpenAI(
    <span class="hljs-comment">#THUDM/glm-4-9b-chat</span>
    <span class="hljs-comment">#Qwen/Qwen2.5-7B-Instruct</span>
    model=<span class="hljs-string">&quot;Qwen/Qwen2.5-7B-Instruct&quot;</span>,
    streaming=<span class="hljs-literal">False</span>,  <span class="hljs-comment"># 启用流式输出</span>
    api_key=os.getenv(<span class="hljs-string">&#x27;SILICONFLOW_API_KEY&#x27;</span>, <span class="hljs-string">&#x27;&#x27;</span>), 
    base_url=os.getenv(<span class="hljs-string">&#x27;SILICONFLOW_BASE_URL&#x27;</span>, <span class="hljs-string">&#x27;&#x27;</span>),
    temperature=<span class="hljs-number">0.1</span>,
)
llm_with_tools = llm.bind_tools(tools)

<span class="hljs-comment"># 创建总结llm，需要使用支持FunctionCalling的模型</span>
summary_llm = ChatOpenAI(
    model=<span class="hljs-string">&quot;THUDM/glm-4-9b-chat&quot;</span>,
    streaming=<span class="hljs-literal">False</span>,
    api_key=os.getenv(<span class="hljs-string">&#x27;SILICONFLOW_API_KEY&#x27;</span>, <span class="hljs-string">&#x27;&#x27;</span>), 
    base_url=os.getenv(<span class="hljs-string">&#x27;SILICONFLOW_BASE_URL&#x27;</span>, <span class="hljs-string">&#x27;&#x27;</span>),
    temperature=<span class="hljs-number">0.1</span>,
)

<span class="hljs-comment"># 创建工具列表的函数版本</span>
functions = [convert_to_openai_function(t) <span class="hljs-keyword">for</span> t <span class="hljs-keyword">in</span> tools]

tools_by_name = &#123;tool.name: tool <span class="hljs-keyword">for</span> tool <span class="hljs-keyword">in</span> tools&#125;

<span class="hljs-comment"># 定义搜索工具节点函数</span>
<span class="hljs-keyword">async</span> <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">search_tool_node</span>(<span class="hljs-params">state: <span class="hljs-built_in">dict</span></span>):</span>
    <span class="hljs-string">&quot;&quot;&quot;搜索工具节点&quot;&quot;&quot;</span>
    result = []
    <span class="hljs-keyword">for</span> tool_call <span class="hljs-keyword">in</span> state[<span class="hljs-string">&quot;messages&quot;</span>][-<span class="hljs-number">1</span>].tool_calls:
        <span class="hljs-keyword">if</span> tool_call[<span class="hljs-string">&quot;name&quot;</span>] == <span class="hljs-string">&quot;search_tool&quot;</span>:
            tool = tools_by_name[tool_call[<span class="hljs-string">&quot;name&quot;</span>]]
            observation = tool.invoke(tool_call[<span class="hljs-string">&quot;args&quot;</span>])
            <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;搜索工具结果的完整输出------&gt;&#x27;</span>,observation,<span class="hljs-string">&#x27;\n&#x27;</span>)
            
            <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(observation, <span class="hljs-built_in">list</span>):
                <span class="hljs-comment"># 如果是数组，直接提取每个对象的URL</span>
                urls = [item.get(<span class="hljs-string">&#x27;url&#x27;</span>, <span class="hljs-string">&#x27;&#x27;</span>) <span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> observation <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(item, <span class="hljs-built_in">dict</span>)]
                search_result = urls
            <span class="hljs-keyword">else</span>:
                <span class="hljs-comment"># 如果不是数组，将整个observation作为结果</span>
                search_result = <span class="hljs-built_in">str</span>(observation)
                
            result.append(ToolMessage(content=search_result, tool_call_id=tool_call[<span class="hljs-string">&quot;id&quot;</span>]))
    <span class="hljs-keyword">return</span> &#123;<span class="hljs-string">&quot;messages&quot;</span>: result&#125;

<span class="hljs-comment"># 爬取网页内容工具节点</span>
<span class="hljs-keyword">async</span> <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">crawl4ai_tool_node</span>(<span class="hljs-params">state: MessagesState</span>):</span>
    <span class="hljs-string">&quot;&quot;&quot;爬取网页内容工具节点&quot;&quot;&quot;</span>
    last_message = state[<span class="hljs-string">&quot;messages&quot;</span>][-<span class="hljs-number">1</span>]
    urls = last_message.content
    
    <span class="hljs-comment"># 调用爬虫工具获取结果</span>
    tool_response = <span class="hljs-keyword">await</span> crawl4ai_tool.ainvoke(&#123;<span class="hljs-string">&quot;query&quot;</span>: urls&#125;)
    
    messages = []
    <span class="hljs-comment"># 创建ToolMessage并添加到列表</span>
    messages.append(ToolMessage(
        content=tool_response.get(<span class="hljs-string">&#x27;result&#x27;</span>, tool_response), 
        tool_call_id=last_message.<span class="hljs-built_in">id</span>
    ))
    
    <span class="hljs-keyword">return</span> &#123;<span class="hljs-string">&quot;messages&quot;</span>: messages&#125;

<span class="hljs-comment"># 定义流式节点函数</span>
<span class="hljs-keyword">async</span> <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">chatbot_node</span>(<span class="hljs-params">state: MessagesState</span>):</span>
    <span class="hljs-string">&quot;&quot;&quot;生成回复的节点函数&quot;&quot;&quot;</span>
    messages = state[<span class="hljs-string">&quot;messages&quot;</span>]
    
    <span class="hljs-comment"># 使用非流式方式接收完整返回</span>
    response = <span class="hljs-keyword">await</span> llm_with_tools.ainvoke(
        messages,
        functions=functions,
        function_call=<span class="hljs-string">&quot;auto&quot;</span>
    )
    <span class="hljs-keyword">return</span> &#123;<span class="hljs-string">&quot;messages&quot;</span>: [response]&#125;

<span class="hljs-comment"># 总结bot节点</span>
<span class="hljs-keyword">async</span> <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">summary_bot_node</span>(<span class="hljs-params">state: MessagesState</span>):</span>
    <span class="hljs-string">&quot;&quot;&quot;总结网页内容的节点&quot;&quot;&quot;</span>
    messages = state[<span class="hljs-string">&quot;messages&quot;</span>]
    
    <span class="hljs-comment"># 找出用户的原始问题</span>
    human_messages = [msg <span class="hljs-keyword">for</span> msg <span class="hljs-keyword">in</span> messages <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(msg, HumanMessage)]
    human_message = human_messages[<span class="hljs-number">0</span>] <span class="hljs-keyword">if</span> human_messages <span class="hljs-keyword">else</span> <span class="hljs-literal">None</span>
    
    <span class="hljs-comment"># 找出最后一个工具消息（包含抓取的网页内容）</span>
    tool_messages = [msg <span class="hljs-keyword">for</span> msg <span class="hljs-keyword">in</span> messages <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(msg, ToolMessage)]
    last_tool_message = <span class="hljs-literal">None</span>
    <span class="hljs-keyword">for</span> msg <span class="hljs-keyword">in</span> <span class="hljs-built_in">reversed</span>(tool_messages):
        <span class="hljs-keyword">if</span> msg.content:
            last_tool_message = msg
            <span class="hljs-keyword">break</span>
    
    <span class="hljs-comment"># 创建系统消息</span>
    system_message = SystemMessage(content=<span class="hljs-string">&quot;&quot;&quot;</span>
<span class="hljs-string">        ## 你是一个擅长信息整理并总结的AI助手，请根据用户的问题，并结合工具给出的信息把回复总结出来。</span>
<span class="hljs-string">        - 如果有工具信息，正常执行总结；如果工具信息里是一些在线pdf，请把pdf的url和标题输出出来，告知用户来源自行查看。</span>
<span class="hljs-string">        - 如果发现工具没有返回信息，如【工具执行异常，无返回结果】，请根据用户的问题，给出简要回答，但必须带上说明，说明你无法生成详细总结的原因。并让用户再次自行尝试。</span>
<span class="hljs-string">        - 风格：排版按照markdown格式输出。热情，专业，有亲和力。</span>
<span class="hljs-string">    &quot;&quot;&quot;</span>)
    
    <span class="hljs-comment"># 构建消息列表</span>
    summary_messages = [system_message]
    
    <span class="hljs-keyword">if</span> human_message:
        summary_messages.append(human_message)
    
    <span class="hljs-keyword">if</span> last_tool_message:
        tool_result_message = ToolMessage(
            content=<span class="hljs-string">f&quot;以下是搜索和网页抓取工具返回的详细结果:\n\n<span class="hljs-subst">&#123;last_tool_message.content&#125;</span>&quot;</span>, 
            tool_call_id=last_tool_message.<span class="hljs-built_in">id</span>
        )
        summary_messages.append(tool_result_message)
    
    <span class="hljs-comment"># 调用摘要模型</span>
    <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(summary_messages) &gt; <span class="hljs-number">1</span>:
        response = <span class="hljs-keyword">await</span> summary_llm.ainvoke(summary_messages)
    <span class="hljs-keyword">else</span>:
        response = ToolMessage(
            content=<span class="hljs-string">&quot;工具执行异常，无返回结果。&quot;</span>, 
            tool_call_id=last_tool_message.<span class="hljs-built_in">id</span> <span class="hljs-keyword">if</span> last_tool_message <span class="hljs-keyword">else</span> <span class="hljs-string">&quot;error&quot;</span>
        )
    
    <span class="hljs-keyword">return</span> &#123;<span class="hljs-string">&quot;messages&quot;</span>: [response]&#125;

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">route_search_tool</span>(<span class="hljs-params">state: MessagesState</span>):</span>
    <span class="hljs-string">&quot;&quot;&quot;</span>
<span class="hljs-string">    在条件边中使用,如果最后一条消息包含搜索工具调用,则路由到搜索工具节点,否则路由到结束节点。</span>
<span class="hljs-string">    &quot;&quot;&quot;</span>
    messages = state[<span class="hljs-string">&#x27;messages&#x27;</span>]
    last_message = messages[-<span class="hljs-number">1</span>]
    
    <span class="hljs-comment"># 检查是否是AI消息且有工具调用</span>
    <span class="hljs-keyword">if</span> <span class="hljs-built_in">hasattr</span>(last_message, <span class="hljs-string">&#x27;tool_calls&#x27;</span>) <span class="hljs-keyword">and</span> last_message.tool_calls:
        <span class="hljs-keyword">for</span> tool_call <span class="hljs-keyword">in</span> last_message.tool_calls:
            <span class="hljs-keyword">if</span> tool_call[<span class="hljs-string">&quot;name&quot;</span>] == <span class="hljs-string">&quot;search_tool&quot;</span>:
                <span class="hljs-keyword">return</span> <span class="hljs-string">&quot;search_tool&quot;</span>
    
    <span class="hljs-keyword">return</span> END

<span class="hljs-comment"># 添加节点到图</span>
graph_builder.add_node(<span class="hljs-string">&quot;chat_bot&quot;</span>, chatbot_node)
graph_builder.add_node(<span class="hljs-string">&quot;search_tool&quot;</span>, search_tool_node)
graph_builder.add_node(<span class="hljs-string">&quot;crawl4ai_tool&quot;</span>, crawl4ai_tool_node)
graph_builder.add_node(<span class="hljs-string">&quot;summary_bot&quot;</span>, summary_bot_node)

<span class="hljs-comment"># 设置入口点</span>
graph_builder.set_entry_point(<span class="hljs-string">&quot;chat_bot&quot;</span>)

<span class="hljs-comment"># 添加条件边</span>
graph_builder.add_conditional_edges(
    <span class="hljs-string">&quot;chat_bot&quot;</span>,
    route_search_tool,
    path_map=&#123;<span class="hljs-string">&quot;search_tool&quot;</span>: <span class="hljs-string">&quot;search_tool&quot;</span>, <span class="hljs-string">&quot;END&quot;</span>: END&#125;
)

<span class="hljs-comment"># 添加其他边</span>
graph_builder.add_edge(<span class="hljs-string">&quot;search_tool&quot;</span>, <span class="hljs-string">&quot;crawl4ai_tool&quot;</span>)
graph_builder.add_edge(<span class="hljs-string">&quot;crawl4ai_tool&quot;</span>, <span class="hljs-string">&quot;summary_bot&quot;</span>)
graph_builder.add_edge(<span class="hljs-string">&quot;summary_bot&quot;</span>, END)

<span class="hljs-comment"># 编译图</span>
graph = graph_builder.<span class="hljs-built_in">compile</span>()

<span class="hljs-comment"># 定义一个将图导出为PNG的函数</span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">export_graph_to_png</span>():</span>
    <span class="hljs-string">&quot;&quot;&quot;</span>
<span class="hljs-string">    将LangGraph图导出为PNG格式</span>
<span class="hljs-string">    </span>
<span class="hljs-string">    Returns:</span>
<span class="hljs-string">        str: 生成的PNG文件路径</span>
<span class="hljs-string">    &quot;&quot;&quot;</span>
    <span class="hljs-keyword">try</span>:
        output_file=<span class="hljs-string">&#x27;web_crawl_graph-&#x27;</span> + datetime.now().strftime(<span class="hljs-string">&quot;%Y-%m-%d_%H-%M-%S&quot;</span>) + <span class="hljs-string">&quot;.png&quot;</span>
        graph.get_graph().draw_mermaid_png(
            draw_method=MermaidDrawMethod.API,
            output_file_path=output_file
        )
    <span class="hljs-keyword">except</span> Exception <span class="hljs-keyword">as</span> e:
        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;导出PNG图形时出错: <span class="hljs-subst">&#123;e&#125;</span>&quot;</span>)
        <span class="hljs-keyword">return</span> <span class="hljs-literal">None</span>

<span class="hljs-comment"># 异步运行函数</span>
<span class="hljs-keyword">async</span> <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">run_demo</span>():</span>
    <span class="hljs-string">&quot;&quot;&quot;异步运行LangGraph流式输出演示&quot;&quot;&quot;</span>
    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;开始流式生成回答...\n&quot;</span>)
    
    today = datetime.now().strftime(<span class="hljs-string">&quot;%Y-%m-%d&quot;</span>)
    
    <span class="hljs-comment"># 创建初始消息</span>
    system_message = SystemMessage(content=<span class="hljs-string">f&quot;&quot;&quot;</span>
<span class="hljs-string">        # 你是一个强大的AI助手，擅长搜索和分析网络信息。</span>
<span class="hljs-string">        ## 对于用户的问题，请先分析是否有足够知识进行回答，否则就要进行网络查询。如果需要查询实时或专业信息，请先使用[搜索工具]获取相关内容的链接。</span>
<span class="hljs-string">        ## 如果[搜索工具]返回的是链接，需要再用[爬虫工具]获取具体内容。</span>
<span class="hljs-string">        ## 请牢记今天的日期是<span class="hljs-subst">&#123;today&#125;</span>。</span>
<span class="hljs-string">    &quot;&quot;&quot;</span>)
    
    first_message = HumanMessage(content=<span class="hljs-string">&quot;&quot;&quot;</span>
<span class="hljs-string">        crawl4ai是什么？</span>
<span class="hljs-string">    &quot;&quot;&quot;</span>)
    
    <span class="hljs-comment"># 初始化状态</span>
    initial_state = &#123;<span class="hljs-string">&quot;messages&quot;</span>: [system_message, first_message]&#125;
    output_list = []
    
    <span class="hljs-keyword">try</span>:
        <span class="hljs-comment"># 异步执行流式输出</span>
        <span class="hljs-keyword">async</span> <span class="hljs-keyword">for</span> event <span class="hljs-keyword">in</span> graph.astream_events(initial_state, config=&#123;<span class="hljs-string">&quot;configurable&quot;</span>: &#123;<span class="hljs-string">&quot;thread_id&quot;</span>: <span class="hljs-string">&quot;8&quot;</span>&#125;&#125;, version=<span class="hljs-string">&quot;v2&quot;</span>):
            <span class="hljs-comment"># 定义一个变量接收所有on_chat_model_stream的值</span>
            <span class="hljs-comment"># print(&#x27;event------&gt;&#x27;,event,&#x27;\n\n&#x27;)</span>
            event_type = event[<span class="hljs-string">&#x27;event&#x27;</span>]
            <span class="hljs-comment"># print(&#x27;event_type------&gt;&#x27;,event_type,&#x27;\n\n&#x27;)</span>
            <span class="hljs-keyword">if</span> event_type == <span class="hljs-string">&#x27;on_tool_start&#x27;</span> <span class="hljs-keyword">and</span> event[<span class="hljs-string">&#x27;data&#x27;</span>]:
                <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;开始调用工具查询&#x27;</span>, event[<span class="hljs-string">&#x27;data&#x27;</span>],<span class="hljs-string">&#x27;\n\n&#x27;</span>)
                <span class="hljs-keyword">pass</span>
            <span class="hljs-keyword">elif</span> event_type == <span class="hljs-string">&#x27;on_tool_end&#x27;</span> <span class="hljs-keyword">and</span> event[<span class="hljs-string">&#x27;data&#x27;</span>]:
                <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;工具查询结束&#x27;</span>,event[<span class="hljs-string">&#x27;data&#x27;</span>],<span class="hljs-string">&#x27;\n\n&#x27;</span>)
                <span class="hljs-keyword">pass</span>
            <span class="hljs-keyword">elif</span> event_type == <span class="hljs-string">&#x27;on_chat_model_stream&#x27;</span>:
                <span class="hljs-comment"># print(&#x27;on_chat_model_stream事件------&gt;&#x27;,event[&quot;data&quot;][&quot;chunk&quot;].content,&#x27;\n\n&#x27;)</span>
                chunk_data = event[<span class="hljs-string">&quot;data&quot;</span>][<span class="hljs-string">&quot;chunk&quot;</span>].content <span class="hljs-comment"># 流式输出的内容</span>
                output_list.append(chunk_data)
                <span class="hljs-built_in">print</span>(chunk_data, end=<span class="hljs-string">&#x27;&#x27;</span>, flush=<span class="hljs-literal">True</span>)
    <span class="hljs-keyword">except</span> Exception <span class="hljs-keyword">as</span> e:
        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;graph.astream_events执行出错: <span class="hljs-subst">&#123;e&#125;</span>&quot;</span>)
    
    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;\n\n&#x27;</span>)
    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;************&#x27;</span>*<span class="hljs-number">10</span>)
    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;生成完成！\n&quot;</span>,<span class="hljs-string">&quot;&quot;</span>.join(output_list),<span class="hljs-string">&#x27;\n\n&#x27;</span>)
    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;************&#x27;</span>*<span class="hljs-number">10</span>)
    
    <span class="hljs-comment"># 展示图形</span>
    <span class="hljs-keyword">try</span>:
        mermaid_diagram = graph.get_graph().draw_mermaid()
        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;```mermaid\n<span class="hljs-subst">&#123;mermaid_diagram&#125;</span>\n```&quot;</span>)
        
        export_graph_to_png()
    <span class="hljs-keyword">except</span> Exception <span class="hljs-keyword">as</span> e:
        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;图表绘制出错: <span class="hljs-subst">&#123;e&#125;</span>&quot;</span>)
    

<span class="hljs-comment"># 执行异步函数</span>
<span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&quot;__main__&quot;</span>:
    asyncio.run(run_demo())</code></pre></div>


<h2 id="10-总结与思考"><a href="#10-总结与思考" class="headerlink" title="10. 总结与思考"></a>10. 总结与思考</h2><p>（<strong>以下为Claude-3.7-sonnet根据6篇博客的一个总结</strong>）</p>
<p>通过前六篇Langgraph学习系列，从最基础的聊天机器人开始，逐步构建出一个能够进行网络搜索和网页内容抓取的复杂AI助手。回顾整个学习过程，可以总结如下几点：</p>
<h3 id="Langgraph工作流理解"><a href="#Langgraph工作流理解" class="headerlink" title="Langgraph工作流理解"></a>Langgraph工作流理解</h3><ol>
<li><strong>节点与状态图</strong>：Langgraph的核心是基于节点和边的状态图，每个节点负责特定功能，通过边连接形成工作流。</li>
<li><strong>状态传递机制</strong>：各节点间通过状态字典传递信息，保证数据在整个工作流中的连贯性。</li>
<li><strong>条件路由</strong>：通过条件函数动态决定执行路径，实现复杂的决策逻辑。</li>
<li><strong>事件监听</strong>：通过<code>astream_events</code>可监听整个工作流的执行过程，包括节点开始、结束、中间输出等。</li>
</ol>
<h3 id="技术演进路线"><a href="#技术演进路线" class="headerlink" title="技术演进路线"></a>技术演进路线</h3><ol>
<li><strong>基础聊天机器人</strong>：实现了简单的用户问答功能（第1篇）</li>
<li><strong>工具调用集成</strong>：让LLM能够根据需要调用工具（第2篇）</li>
<li><strong>搜索工具对比</strong>：探索不同搜索API的特点和适用场景（第3篇）</li>
<li><strong>Web搜索集成</strong>：构建能够搜索网络信息的AI助手（第4篇）</li>
<li><strong>ai爬取工具的使用</strong>：集成Crawl4AI等专为大语言模型设计的爬虫工具，实现对网页内容的高效抓取（第5篇）</li>
<li><strong>网页内容抓取</strong>：扩展助手能力，实现对网页内容的深度分析（第6篇）</li>
</ol>
<h3 id="关键技术点"><a href="#关键技术点" class="headerlink" title="关键技术点"></a>关键技术点</h3><ol>
<li><strong>工具函数封装</strong>：使用<code>@tool</code>装饰器将普通函数转化为LLM可调用的工具。</li>
<li><strong>自定义节点</strong>：根据不同需求实现特定功能的节点函数。</li>
<li><strong>格式处理</strong>：解决工具返回结果与LLM兼容性问题。</li>
<li><strong>System Prompt设计</strong>：精心设计系统提示，引导LLM正确使用工具。</li>
<li><strong>链式处理</strong>：实现”搜索→抓取→总结”的完整信息处理流程。</li>
</ol>
<h3 id="实用价值"><a href="#实用价值" class="headerlink" title="实用价值"></a>实用价值</h3><p>通过这个系列，我们构建了一个实用的AI助手，它不仅能回答常规问题，还能：</p>
<ul>
<li>根据需要自主决定是否搜索网络信息</li>
<li>获取最新的互联网信息</li>
<li>抓取完整的网页内容进行深度分析</li>
<li>综合多个信息源生成更全面的回答</li>
</ul>
<p>这样的助手在实际应用中具有很高的价值，可以帮助用户获取更准确、更全面的信息，而不仅仅局限于LLM训练数据中的知识。</p>
<h3 id="未来改进方向"><a href="#未来改进方向" class="headerlink" title="未来改进方向"></a>未来改进方向</h3><p>在接下来的学习中，还可以考虑以下方向的扩展：</p>
<ol>
<li><strong>历史会话管理</strong>：实现对话历史的保存和管理</li>
<li><strong>多工具协同</strong>：集成更多工具，如文档解析等</li>
<li><strong>记忆与学习</strong>：让助手能记住用户偏好和之前的交互</li>
<li><strong>UI集成</strong>：将助手集成到Web界面或其他应用中</li>
</ol>
<p>通过Langgraph，我们看到了构建复杂AI工作流的强大可能性，它提供了一种灵活且可扩展的方式来组织和管理LLM的行为，使AI助手能够完成更加复杂的任务。</p>

            </div>
            <hr>
            <div>
              <div class="post-metas mb-3">
                
                  <div class="post-meta mr-3">
                    <i class="iconfont icon-category"></i>
                    
                      <a class="hover-with-bg" href="/categories/AI%E7%9B%B8%E5%85%B3/">AI相关</a>
                    
                  </div>
                
                
                  <div class="post-meta">
                    <i class="iconfont icon-tags"></i>
                    
                      <a class="hover-with-bg" href="/tags/Langgraph/">Langgraph</a>
                    
                  </div>
                
              </div>
              
                <p class="note note-warning">
                  
                    本博客所有文章除特别声明外，均采用 <a target="_blank" href="https://creativecommons.org/licenses/by-sa/4.0/deed.zh" rel="nofollow noopener noopener">CC BY-SA 4.0 协议</a> ，转载请注明出处！
                  
                </p>
              
              
                <div class="post-prevnext">
                  <article class="post-prev col-6">
                    
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2025/04/12/Langgraph%E5%AD%A6%E4%B9%A05%EF%BC%9A%E5%B0%9D%E8%AF%95AI%E7%88%AC%E5%8F%96%E5%B7%A5%E5%85%B7crawl4ai/">
                        <span class="hidden-mobile">Langgraph学习5：AI爬取工具crawl4ai</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>
    
      <div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn">
        <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div class="toc-body" id="toc-body"></div>
</div>

      </div>
    
  </div>
</div>

<!-- Custom -->


    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
    

    
  </main>

  <footer class="text-center mt-5 py-3">
  <div class="footer-content">
     <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/wenkil" target="_blank" rel="nofollow noopener"><span>My Github</span></a> 
  </div>
  

  
  <!-- 备案信息 -->
  <div class="beian">
    <span>
      <a href="http://beian.miit.gov.cn/" target="_blank" rel="nofollow noopener">
        
      </a>
    </span>
    
  </div>


  
</footer>


  <!-- SCRIPTS -->
  
  <script  src="https://cdn.jsdelivr.net/npm/nprogress@0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/nprogress@0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js" ></script>
<script  src="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>

<!-- Plugins -->


  <script  src="/js/local-search.js" ></script>



  
    <script  src="/js/img-lazyload.js" ></script>
  



  



  
    <script  src="https://cdn.jsdelivr.net/npm/tocbot@4/dist/tocbot.min.js" ></script>
  
  
    <script  src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3/dist/jquery.fancybox.min.js" ></script>
  
  
    <script  src="https://cdn.jsdelivr.net/npm/anchor-js@4/anchor.min.js" ></script>
  
  
    <script defer src="https://cdn.jsdelivr.net/npm/clipboard@2/dist/clipboard.min.js" ></script>
  






  <script  src="https://cdn.jsdelivr.net/npm/typed.js@2/lib/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var title = document.getElementById('subtitle').title;
      
      typing(title)
      
    })(window, document);
  </script>















<!-- 主题的启动项 保持在最底部 -->
<script  src="/js/boot.js" ></script>


</body>
</html>
